{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/silas.rudolf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "from rouge.rouge_score import *\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "def read_list_asline(path):\n",
    "    data = []\n",
    "    with open(path,'r',encoding='utf-8')  as file:\n",
    "        for line in file:\n",
    "            data.append(line.strip())\n",
    "    return data\n",
    "\n",
    "\n",
    "def download_nltk():\n",
    "    try:\n",
    "        _create_unverified_https_context = ssl._create_unverified_context\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "def _text_to_ngrams(text, n=1):\n",
    "    ngrams = list(nltk.ngrams(nltk.word_tokenize(text), n))\n",
    "    return Ngrams(ngrams)\n",
    "\n",
    "def _get_rouge_from_ngram(reference_ngrams: Ngrams, evaluated_ngrams: Ngrams)-> dict:\n",
    "    reference_count = len(reference_ngrams)\n",
    "    evaluated_count = len(evaluated_ngrams)\n",
    "\n",
    "    # Gets the overlapping ngrams between evaluated and reference\n",
    "    overlapping_ngrams = evaluated_ngrams.intersection(reference_ngrams)\n",
    "    overlapping_count = len(overlapping_ngrams)\n",
    "    return f_r_p_rouge_n(evaluated_count, reference_count, overlapping_count)\n",
    "\n",
    "download_nltk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "# This function is faster than seg_based_on_rouge because it uses the ngrams to computer rouge rather than text.\n",
    "def fast_rouge(sou, tar, name=None, verbose=False):\n",
    "    cur_new = ''\n",
    "    cur_ngram = Ngrams()\n",
    "    best_score = 0\n",
    "    best_sents = []\n",
    "\n",
    "    # use ngram to represent each text\n",
    "    sou = _text_to_ngrams(sou)\n",
    "    seg = [(x, _text_to_ngrams(x), i) for i, x in enumerate(nltk.sent_tokenize(tar))]\n",
    "\n",
    "    tot_len = len(seg)\n",
    "    for i in range(min(MAX_LENGTH, tot_len)):\n",
    "        scores = [(x, _get_rouge_from_ngram(cur_ngram.union(seg_ngram), sou), i) for x, seg_ngram, i in seg]\n",
    "        best_seg = max(scores, key=lambda x: x[1]['f'])\n",
    "        seg = [x for x in seg if x[2] != best_seg[2]]  # remove dup\n",
    "        cur_new += ' ' + best_seg[0]\n",
    "        cur_ngram = _text_to_ngrams(cur_new)\n",
    "        cur_score = _get_rouge_from_ngram(cur_ngram, sou)['f']\n",
    "        if cur_score > best_score:\n",
    "            best_score = cur_score\n",
    "            best_sents.append(best_seg)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print(\"id:\", name, \"input/output:\", tot_len, len(best_sents), \"best:\", best_score)\n",
    "    best_string = list(set((x[0], x[2]) for x in best_sents))\n",
    "    best_string.sort(key=lambda x: x[1])\n",
    "    best_string = ' '.join([x[0] for x in best_string])\n",
    "\n",
    "    return best_sents, best_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('in the last 25 days.',\n",
       "   {'f': 0.2727272703719008, 'p': 0.15789473684210525, 'r': 1.0},\n",
       "   9),\n",
       "  ('21 % of conversions.',\n",
       "   {'f': 0.4166666633680556, 'p': 0.2631578947368421, 'r': 1.0},\n",
       "   4),\n",
       "  ('average client is.',\n",
       "   {'f': 0.5098039177700885, 'p': 0.34210526315789475, 'r': 1.0},\n",
       "   8),\n",
       "  ('excited about.',\n",
       "   {'f': 0.5660377317906728, 'p': 0.39473684210526316, 'r': 1.0},\n",
       "   1),\n",
       "  ('showed him.',\n",
       "   {'f': 0.6181818139107438, 'p': 0.4473684210526316, 'r': 1.0},\n",
       "   13),\n",
       "  ('weeks .', {'f': 0.642857138494898, 'p': 0.47368421052631576, 'r': 1.0}, 3),\n",
       "  ('problem . . the.', {'f': 0.6666666622222223, 'p': 0.5, 'r': 1.0}, 12)],\n",
       " 'excited about. weeks . 21 % of conversions. average client is. in the last 25 days. problem . . the. showed him.')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar = '[CLS] marco. excited about. conversions in. weeks . 21 % of conversions. % of conversions. of conversions. the client. average client is. in the last 25 days. last 25 days. 25 days. problem . . the. showed him. him . the client. ##k ##b. z ##k ##b. k ##lar ##a. ##lar ##a. z ##k ##b. ##k ##b. same problem . problem .'\n",
    "sou = 'Marco was at a meeting yesterday. The client was excited about the insights they showed him. They lost 21% of conversions in 3 weeks. The average client is losing 41% in the last 25 days. Klara and ZKB have the same problem.'\n",
    "\n",
    "fast_rouge(sou, tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d10268de14796ab72802f3d5204661607cb47f5caae6ef1d9733064b38c2714"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('locator_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
